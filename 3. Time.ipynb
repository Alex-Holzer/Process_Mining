{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"Raw/data.csv\", header=True, inferSchema=False, sep=\";\")\n",
    "df = df.withColumn(\"Datum\", F.to_timestamp(\"Datum\", \"d.M.yy h:mm\"))\n",
    "# drop cases with missing case_key\n",
    "df = df.filter(F.col(\"case_key\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_time_dist(\n",
    "    df: DataFrame, event: str, timestamp: str, time_var: str\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of occurrences of each event over the specified time variable and return the result as a dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input dataframe.\n",
    "        event (str): The column name for the event.\n",
    "        timestamp (str): The column name for the timestamp.\n",
    "        time_var (str): The time variable to group by (hour, day, week, or month).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The dataframe with the number of occurrences of each event over the specified time variable.\n",
    "\n",
    "    Example:\n",
    "        result_df = calculate_event_occurrences(df, \"Funktion\", \"Timestamp\", \"hour\")\n",
    "    \"\"\"\n",
    "    if time_var == \"hour\":\n",
    "        df = df.withColumn(time_var, F.hour(F.col(timestamp)))\n",
    "    elif time_var == \"day\":\n",
    "        df = df.withColumn(time_var, F.dayofmonth(F.col(timestamp)))\n",
    "    elif time_var == \"week\":\n",
    "        df = df.withColumn(time_var, F.weekofyear(F.col(timestamp)))\n",
    "    elif time_var == \"month\":\n",
    "        df = df.withColumn(time_var, F.month(F.col(timestamp)))\n",
    "    elif time_var == \"year\":\n",
    "        df = df.withColumn(time_var, F.year(F.col(timestamp)))\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_var. Choose from 'hour', 'day', 'week', or 'month'.\"\n",
    "        )\n",
    "\n",
    "    df_event_occurrences = df.groupBy(event, time_var).count().orderBy(event, time_var)\n",
    "\n",
    "    return df_event_occurrences\n",
    "\n",
    "\n",
    "event_time_dist(df, \"Funktion\", \"Datum\", \"year\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration between events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_throughput_time(\n",
    "    df: DataFrame, case_column: str, timestamp_column: str, time_unit: str\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the time difference from the first event to the last event for each case and return the result as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        case_column (str): The column name for the case key.\n",
    "        timestamp_column (str): The column name for the timestamp.\n",
    "        time_unit (str): The time unit to measure the time difference (seconds, minutes, hours, or days).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with the time difference from the first event to the last event for each case.\n",
    "\n",
    "    Example:\n",
    "        result_df = calculate_case_throughput_time(df, \"Case_Key\", \"Timestamp\", \"seconds\")\n",
    "        result_df.show()\n",
    "    \"\"\"\n",
    "    # Define the window specification\n",
    "    window_spec = Window.partitionBy(case_column)\n",
    "\n",
    "    # Calculate the first and last timestamp for each case\n",
    "    df = df.withColumn(\"first_timestamp\", F.min(timestamp_column).over(window_spec))\n",
    "    df = df.withColumn(\"last_timestamp\", F.max(timestamp_column).over(window_spec))\n",
    "\n",
    "    # Calculate the time difference in seconds\n",
    "    df = df.withColumn(\n",
    "        \"time_difference_seconds\",\n",
    "        F.unix_timestamp(\"last_timestamp\") - F.unix_timestamp(\"first_timestamp\"),\n",
    "    )\n",
    "\n",
    "    # Convert the time difference to the specified unit\n",
    "    conversion_factors = {\"seconds\": 1, \"minutes\": 60, \"hours\": 3600, \"days\": 86400}\n",
    "\n",
    "    if time_unit not in conversion_factors:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_unit. Choose from 'seconds', 'minutes', 'hours', or 'days'.\"\n",
    "        )\n",
    "\n",
    "    conversion_factor = conversion_factors[time_unit]\n",
    "    df = df.withColumn(\n",
    "        \"time_difference\", F.col(\"time_difference_seconds\") / conversion_factor\n",
    "    )\n",
    "\n",
    "    # Select the required columns and remove duplicates\n",
    "    result_df = df.select(\n",
    "        case_column, \"first_timestamp\", \"last_timestamp\", \"time_difference\"\n",
    "    ).distinct()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# result_df = calculate_case_throughput_time(df, \"Case_Key\", \"Datum\", \"minutes\")\n",
    "# result_df.show(truncate=False)\n",
    "case_throughput_time(df, \"case_key\", \"Datum\", \"minutes\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_duration_stats(\n",
    "    df: DataFrame,\n",
    "    case_column: str,\n",
    "    timestamp_column: str,\n",
    "    event_column: str,\n",
    "    start_event: str,\n",
    "    end_event: str,\n",
    "    time_unit: str,\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate statistics on the duration between start and end events for each case and return the result as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        case_column (str): The column name for the case key.\n",
    "        timestamp_column (str): The column name for the timestamp.\n",
    "        event_column (str): The column name for the event.\n",
    "        start_event (str): The name of the start event.\n",
    "        end_event (str): The name of the end event.\n",
    "        time_unit (str): The time unit to measure the duration (seconds, minutes, hours, or days).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with statistics on the duration between the start and end events for each case.\n",
    "\n",
    "    Example:\n",
    "        result_df = calculate_event_duration_stats(df, \"CASE_KEY\", \"Datum\", \"Funktion\", \"Antrag Start\", \"Sync\", \"minutes\")\n",
    "        result_df.show(truncate=False)\n",
    "    \"\"\"\n",
    "    # Check if the necessary columns exist in the DataFrame\n",
    "    required_columns = {case_column, timestamp_column, event_column}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        missing_cols = required_columns - set(df.columns)\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "\n",
    "    # Filter for start and end events and rename timestamp columns\n",
    "    start_df = (\n",
    "        df.filter(F.col(event_column) == start_event)\n",
    "        .select(case_column, timestamp_column)\n",
    "        .withColumnRenamed(timestamp_column, \"start_timestamp\")\n",
    "    )\n",
    "    end_df = (\n",
    "        df.filter(F.col(event_column) == end_event)\n",
    "        .select(case_column, timestamp_column)\n",
    "        .withColumnRenamed(timestamp_column, \"end_timestamp\")\n",
    "    )\n",
    "\n",
    "    # Check if the start and end DataFrames are not empty\n",
    "    if start_df.count() == 0:\n",
    "        raise ValueError(f\"No rows with event '{start_event}'\")\n",
    "    if end_df.count() == 0:\n",
    "        raise ValueError(f\"No rows with event '{end_event}'\")\n",
    "\n",
    "    # Join start and end DataFrames on case key\n",
    "    duration_df = start_df.join(end_df, on=case_column)\n",
    "\n",
    "    # Calculate the duration in seconds\n",
    "    duration_df = duration_df.withColumn(\n",
    "        \"duration_seconds\",\n",
    "        F.unix_timestamp(\"end_timestamp\") - F.unix_timestamp(\"start_timestamp\"),\n",
    "    )\n",
    "\n",
    "    # Convert the duration to the specified time unit\n",
    "    time_units = {\"seconds\": 1, \"minutes\": 60, \"hours\": 3600, \"days\": 86400}\n",
    "    if time_unit not in time_units:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_unit. Choose from 'seconds', 'minutes', 'hours', or 'days'.\"\n",
    "        )\n",
    "\n",
    "    conversion_factor = time_units[time_unit]\n",
    "    duration_df = duration_df.withColumn(\n",
    "        \"duration\", F.col(\"duration_seconds\") / conversion_factor\n",
    "    )\n",
    "\n",
    "    # Calculate statistical measures on the duration\n",
    "    stats_df = duration_df.agg(\n",
    "        F.sum(\"duration\").alias(f\"total_duration_{time_unit}\"),\n",
    "        F.avg(\"duration\").alias(f\"average_duration_{time_unit}\"),\n",
    "        F.expr(\"percentile_approx(duration, 0.5)\").alias(\n",
    "            f\"median_duration_{time_unit}\"\n",
    "        ),\n",
    "        F.min(\"duration\").alias(f\"min_duration_{time_unit}\"),\n",
    "        F.max(\"duration\").alias(f\"max_duration_{time_unit}\"),\n",
    "        (F.max(\"duration\") - F.min(\"duration\")).alias(f\"range_duration_{time_unit}\"),\n",
    "        F.variance(\"duration\").alias(f\"variance_duration_{time_unit}\"),\n",
    "        F.stddev(\"duration\").alias(f\"stddev_duration_{time_unit}\"),\n",
    "        F.skewness(\"duration\").alias(f\"skewness_duration_{time_unit}\"),\n",
    "        F.kurtosis(\"duration\").alias(f\"kurtosis_duration_{time_unit}\"),\n",
    "    )\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result_df = event_duration_stats(\n",
    "    df, \"CASE_KEY\", \"Datum\", \"Funktion\", \"Antrag Start\", \"Sync\", \"minutes\"\n",
    ")\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def throughput_time_stats(\n",
    "    df: DataFrame,\n",
    "    case_column: str,\n",
    "    timestamp_column: str,\n",
    "    event_column: str,\n",
    "    time_unit: str,\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate statistics on the throughput time for each event and return the result as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        case_column (str): The column name for the case key.\n",
    "        timestamp_column (str): The column name for the timestamp.\n",
    "        event_column (str): The column name for the event.\n",
    "        time_unit (str): The time unit to measure the duration (seconds, minutes, hours, or days).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with statistics on the throughput time for each event.\n",
    "\n",
    "    Example:\n",
    "        result_df = calculate_throughput_time_stats(df, \"CASE_KEY\", \"Datum\", \"Funktion\", \"minutes\")\n",
    "        result_df.show(truncate=False)\n",
    "    \"\"\"\n",
    "    # Check if the necessary columns exist in the DataFrame\n",
    "    required_columns = {case_column, timestamp_column, event_column}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        missing_cols = required_columns - set(df.columns)\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "\n",
    "    # Add a column with Unix timestamps\n",
    "    df = df.withColumn(\"unix_timestamp\", F.unix_timestamp(timestamp_column))\n",
    "\n",
    "    # Determine the time conversion factor\n",
    "    time_units = {\"seconds\": 1, \"minutes\": 60, \"hours\": 3600, \"days\": 86400}\n",
    "    if time_unit not in time_units:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_unit. Choose from 'seconds', 'minutes', 'hours', or 'days'.\"\n",
    "        )\n",
    "\n",
    "    time_factor = time_units[time_unit]\n",
    "\n",
    "    # Calculate the duration for each event\n",
    "    duration_df = df.groupBy(event_column).agg(\n",
    "        ((F.max(\"unix_timestamp\") - F.min(\"unix_timestamp\")) / time_factor).alias(\n",
    "            f\"duration_{time_unit}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Calculate statistical measures on the duration\n",
    "    stats_df = duration_df.agg(\n",
    "        F.avg(f\"duration_{time_unit}\").alias(f\"average_duration_{time_unit}\"),\n",
    "        F.expr(f\"percentile_approx(duration_{time_unit}, 0.5)\").alias(\n",
    "            f\"median_duration_{time_unit}\"\n",
    "        ),\n",
    "        F.min(f\"duration_{time_unit}\").alias(f\"min_duration_{time_unit}\"),\n",
    "        F.max(f\"duration_{time_unit}\").alias(f\"max_duration_{time_unit}\"),\n",
    "        F.variance(f\"duration_{time_unit}\").alias(\n",
    "            f\"variance_duration_{time_unit}\"),\n",
    "        F.stddev(f\"duration_{time_unit}\").alias(\n",
    "            f\"stddev_duration_{time_unit}\"),\n",
    "        F.skewness(f\"duration_{time_unit}\").alias(\n",
    "            f\"skewness_duration_{time_unit}\"),\n",
    "        F.kurtosis(f\"duration_{time_unit}\").alias(\n",
    "            f\"kurtosis_duration_{time_unit}\"),\n",
    "    )\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result_df = throughput_time_stats(\n",
    "    df, \"CASE_KEY\", \"Datum\", \"Funktion\", \"minutes\")\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_transition_duration(\n",
    "    df: DataFrame,\n",
    "    case_column: str,\n",
    "    timestamp_column: str,\n",
    "    event_column: str,\n",
    "    time_unit: str,\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the duration of transitions between events and return the result as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        case_column (str): The column name for the case key.\n",
    "        timestamp_column (str): The column name for the timestamp.\n",
    "        event_column (str): The column name for the event.\n",
    "        time_unit (str): The time unit to measure the duration (seconds, minutes, hours, or days).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with statistics on the duration of transitions between events.\n",
    "\n",
    "    Example:\n",
    "        result_df = calculate_event_transition_duration(df, \"case_key\", \"Datum\", \"Funktion\", \"minutes\")\n",
    "        result_df.show(truncate=False)\n",
    "    \"\"\"\n",
    "    # Add a column with Unix timestamps\n",
    "    df = df.withColumn(\"unix_timestamp\", F.unix_timestamp(timestamp_column))\n",
    "\n",
    "    # Determine the time conversion factor\n",
    "    time_units = {\"seconds\": 1, \"minutes\": 60, \"hours\": 3600, \"days\": 86400}\n",
    "    if time_unit not in time_units:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_unit. Choose from 'seconds', 'minutes', 'hours', or 'days'.\"\n",
    "        )\n",
    "\n",
    "    time_factor = time_units[time_unit]\n",
    "\n",
    "    # Define the window specification\n",
    "    window_spec = Window.partitionBy(case_column).orderBy(\"unix_timestamp\")\n",
    "\n",
    "    # Calculate the transition and duration\n",
    "    df = df.withColumn(\"next_event\", F.lead(event_column).over(window_spec))\n",
    "    df = df.withColumn(\"prev_timestamp\", F.lag(\n",
    "        \"unix_timestamp\").over(window_spec))\n",
    "    df = df.withColumn(\n",
    "        f\"duration_{time_unit}\",\n",
    "        (F.col(\"unix_timestamp\") - F.col(\"prev_timestamp\")) / time_factor,\n",
    "    )\n",
    "    df = df.withColumn(\"transition\", F.concat_ws(\n",
    "        \" -> \", event_column, \"next_event\"))\n",
    "\n",
    "    # Filter out rows where the next_event is null (end of case)\n",
    "    df = df.filter(F.col(\"next_event\").isNotNull())\n",
    "\n",
    "    # Calculate statistical measures on the duration\n",
    "    stats_df = (\n",
    "        df.groupBy(\"transition\")\n",
    "        .agg(\n",
    "            F.avg(f\"duration_{time_unit}\").alias(f\"mean_duration_{time_unit}\"),\n",
    "            F.expr(f\"percentile_approx(duration_{time_unit}, 0.5)\").alias(\n",
    "                f\"median_duration_{time_unit}\"\n",
    "            ),\n",
    "            F.min(f\"duration_{time_unit}\").alias(f\"min_duration_{time_unit}\"),\n",
    "            F.max(f\"duration_{time_unit}\").alias(f\"max_duration_{time_unit}\"),\n",
    "            F.variance(f\"duration_{time_unit}\").alias(f\"variance_{time_unit}\"),\n",
    "            F.stddev(f\"duration_{time_unit}\").alias(f\"stddev_{time_unit}\"),\n",
    "            F.skewness(f\"duration_{time_unit}\").alias(f\"skewness_{time_unit}\"),\n",
    "            F.kurtosis(f\"duration_{time_unit}\").alias(f\"kurtosis_{time_unit}\"),\n",
    "            (F.max(f\"duration_{time_unit}\") - F.min(f\"duration_{time_unit}\")).alias(\n",
    "                f\"range_{time_unit}\"\n",
    "            ),\n",
    "        )\n",
    "        .orderBy(F.desc(f\"mean_duration_{time_unit}\"))\n",
    "    )\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result_df = event_transition_duration(\n",
    "    df, \"case_key\", \"Datum\", \"Funktion\", \"minutes\")\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_event_duration_comparison(\n",
    "    df: DataFrame, case_key: str, timestamp: str, event: str, time_var: str\n",
    ") -> DataFrame:\n",
    "    # Mapping for time conversion factors\n",
    "    time_factors = {\"seconds\": 1, \"minutes\": 60, \"hours\": 3600, \"days\": 86400}\n",
    "\n",
    "    if time_var not in time_factors:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_var. Choose from 'seconds', 'minutes', 'hours', or 'days'.\"\n",
    "        )\n",
    "\n",
    "    time_factor = time_factors[time_var]\n",
    "\n",
    "    # Add unix timestamp column\n",
    "    df = df.withColumn(\"unix_timestamp\", F.unix_timestamp(timestamp))\n",
    "\n",
    "    # Define window for partitioning by case key and ordering by timestamp\n",
    "    window = Window.partitionBy(case_key).orderBy(\"unix_timestamp\")\n",
    "\n",
    "    # Calculate next event, transition, and duration\n",
    "    df = (\n",
    "        df.withColumn(\"next_event\", F.lead(event).over(window))\n",
    "        .withColumn(\"transition\", F.concat_ws(\" -> \", event, \"next_event\"))\n",
    "        .withColumn(\"prev_timestamp\", F.lag(\"unix_timestamp\").over(window))\n",
    "        .withColumn(\n",
    "            f\"duration_{time_var}\",\n",
    "            (F.col(\"unix_timestamp\") - F.col(\"prev_timestamp\")) / time_factor,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Filter out null transitions and cache the DataFrame\n",
    "    df = df.filter(F.col(\"transition\").isNotNull()).cache()\n",
    "\n",
    "    # Calculate mean, median, and mean absolute deviation in a single groupBy operation\n",
    "    agg_expr = {\n",
    "        f\"duration_{time_var}\": \"avg\",\n",
    "        f\"duration_{time_var}\": \"percentile_approx(0.5)\",\n",
    "        f\"absolute_deviation_{time_var}\": \"avg\",\n",
    "    }\n",
    "\n",
    "    mean_durations = (\n",
    "        df.withColumn(\n",
    "            f\"absolute_deviation_{time_var}\",\n",
    "            F.abs(\n",
    "                F.col(f\"duration_{time_var}\")\n",
    "                - F.avg(f\"duration_{time_var}\").over(window)\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"transition\")\n",
    "        .agg(\n",
    "            F.avg(f\"duration_{time_var}\").alias(\n",
    "                f\"mean_transition_duration_{time_var}\"),\n",
    "            F.expr(f\"percentile_approx(duration_{time_var}, 0.5)\").alias(\n",
    "                f\"median_transition_duration_{time_var}\"\n",
    "            ),\n",
    "            F.avg(f\"absolute_deviation_{time_var}\").alias(\n",
    "                f\"mean_absolute_deviation_{time_var}\"\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Use broadcast join if the mean_durations DataFrame is small\n",
    "    df = df.join(broadcast(mean_durations), on=\"transition\", how=\"left\")\n",
    "\n",
    "    # Calculate percentage deviations\n",
    "    df = df.withColumn(\n",
    "        f\"percentage_deviation_{time_var}\",\n",
    "        (\n",
    "            (\n",
    "                F.col(f\"duration_{time_var}\")\n",
    "                - F.col(f\"mean_transition_duration_{time_var}\")\n",
    "            )\n",
    "            / F.col(f\"mean_transition_duration_{time_var}\")\n",
    "        )\n",
    "        * 100,\n",
    "    ).withColumn(\n",
    "        f\"percentage_median_deviation_{time_var}\",\n",
    "        (\n",
    "            (\n",
    "                F.col(f\"duration_{time_var}\")\n",
    "                - F.col(f\"median_transition_duration_{time_var}\")\n",
    "            )\n",
    "            / F.col(f\"median_transition_duration_{time_var}\")\n",
    "        )\n",
    "        * 100,\n",
    "    )\n",
    "\n",
    "    # Order the DataFrame by mean transition duration and select required columns\n",
    "    df = df.orderBy(F.col(f\"mean_transition_duration_{time_var}\").desc()).select(\n",
    "        case_key,\n",
    "        \"transition\",\n",
    "        f\"duration_{time_var}\",\n",
    "        f\"mean_transition_duration_{time_var}\",\n",
    "        f\"percentage_deviation_{time_var}\",\n",
    "        f\"median_transition_duration_{time_var}\",\n",
    "        f\"percentage_median_deviation_{time_var}\",\n",
    "        f\"mean_absolute_deviation_{time_var}\",\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "result_df = case_event_duration_comparison(\n",
    "    df, \"CASE_KEY\", \"Datum\", \"Funktion\", \"minutes\"\n",
    ")\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_most_frequent_sequence_all_events(\n",
    "    df: DataFrame, case_key: str, event: str, timestamp: str, time_var: str\n",
    ") -> DataFrame:\n",
    "    df = df.withColumn(\"unix_timestamp\", F.unix_timestamp(timestamp))\n",
    "\n",
    "    if time_var == \"seconds\":\n",
    "        time_factor = 1\n",
    "    elif time_var == \"minutes\":\n",
    "        time_factor = 60\n",
    "    elif time_var == \"hours\":\n",
    "        time_factor = 3600\n",
    "    elif time_var == \"days\":\n",
    "        time_factor = 86400\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid time_var. Choose from 'seconds', 'minutes', 'hours', or 'days'.\"\n",
    "        )\n",
    "\n",
    "    window = Window.partitionBy(case_key).orderBy(\"unix_timestamp\")\n",
    "\n",
    "    df = df.withColumn(\"next_event\", F.lead(event).over(window))\n",
    "\n",
    "    df_event_sequence = df.filter(F.col(\"next_event\").isNotNull())\n",
    "\n",
    "    df_event_sequence = df_event_sequence.withColumn(\n",
    "        \"event_sequence\", F.concat(F.col(event), F.lit(\" -> \"), F.col(\"next_event\"))\n",
    "    )\n",
    "\n",
    "    df_event_sequence = df_event_sequence.groupBy(case_key).agg(\n",
    "        F.collect_list(\"event_sequence\").alias(\"event_sequence\"),\n",
    "        (F.last(\"unix_timestamp\") - F.first(\"unix_timestamp\")).alias(\"duration\"),\n",
    "    )\n",
    "\n",
    "    df_event_sequence = df_event_sequence.withColumn(\n",
    "        \"event_sequence\", F.concat_ws(\", \", \"event_sequence\")\n",
    "    )\n",
    "\n",
    "    df_event_sequence = df_event_sequence.withColumn(\n",
    "        f\"duration_{time_var}\", F.col(\"duration\") / time_factor\n",
    "    )\n",
    "\n",
    "    df_most_frequent_sequence_all_events = (\n",
    "        df_event_sequence.groupBy(\"event_sequence\")\n",
    "        .agg(\n",
    "            F.count(case_key).alias(\"count\"),\n",
    "            F.min(f\"duration_{time_var}\").alias(f\"min_duration_{time_var}\"),\n",
    "            F.max(f\"duration_{time_var}\").alias(f\"max_duration_{time_var}\"),\n",
    "            F.mean(f\"duration_{time_var}\").alias(f\"mean_duration_{time_var}\"),\n",
    "            F.expr(f\"percentile_approx(duration_{time_var}, 0.5)\").alias(\n",
    "                f\"median_duration_{time_var}\"\n",
    "            ),\n",
    "            F.variance(f\"duration_{time_var}\").alias(f\"variance_{time_var}\"),\n",
    "            F.stddev(f\"duration_{time_var}\").alias(f\"stddev_{time_var}\"),\n",
    "            F.kurtosis(f\"duration_{time_var}\").alias(f\"kurtosis_{time_var}\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            f\"range_{time_var}\",\n",
    "            F.col(f\"max_duration_{time_var}\") - F.col(f\"min_duration_{time_var}\"),\n",
    "        )\n",
    "        .orderBy(F.desc(\"count\"))\n",
    "    )\n",
    "\n",
    "    total_count = df_most_frequent_sequence_all_events.select(F.sum(\"count\")).first()[0]\n",
    "\n",
    "    df_most_frequent_sequence_all_events = (\n",
    "        df_most_frequent_sequence_all_events.withColumn(\n",
    "            \"percentage\", (F.col(\"count\") / total_count) * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_most_frequent_sequence_all_events\n",
    "\n",
    "\n",
    "calculate_most_frequent_sequence_all_events(\n",
    "    df, \"case_key\", \"Funktion\", \"Datum\", \"minutes\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
